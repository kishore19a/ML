{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  8]\n",
      " [ 7  9]\n",
      " [ 6 10]\n",
      " [ 5 12]]\n",
      "[4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "# Create a basic dataset\n",
    "df = pd.DataFrame([[8, 8, 4], [7, 9, 5], [6, 10, 6], [5, 12, 7]], columns=['cgpa', 'resumeScore', 'package'])\n",
    "X = df.iloc[:, 0:2].values\n",
    "y = df.iloc[:, -1].values\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(nnDims):\n",
    "    locWeights = {}\n",
    "    L = len(nnDims)\n",
    "    for l in range(1, L):\n",
    "        locWeights['W' + str(l)] = np.ones((nnDims[l-1], nnDims[l])) * 0.1\n",
    "        locWeights['B' + str(l)] = np.zeros(nnDims[l])\n",
    "\n",
    "    return locWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(aPrev, W, B):\n",
    "    return (np.dot(W.T, aPrev) + B)\n",
    "\n",
    "def forward_propogate(Xi, weights):\n",
    "\n",
    "    # Half the size of W,b dictionary\n",
    "    L = len(weights) // 2 \n",
    "\n",
    "    # a[0] = input = Xi\n",
    "    A = Xi\n",
    "\n",
    "    for l in range(1, L + 1):\n",
    "        APrev = A\n",
    "        Wl = weights['W' + str(l)]\n",
    "        Bl = weights['B' + str(l)]\n",
    "        # print('a[' + str(l-1) + ']: ', APrev)\n",
    "        # print('W[' + str(l) + ']: ', Wl)\n",
    "        # print('B[' + str(l) + ']: ', Bl)\n",
    "        # print('--'*20)\n",
    "\n",
    "        A = linear_forward(APrev, Wl, Bl)\n",
    "        # print('a['+str(l)+']: ', A)\n",
    "        # print('**'*20)\n",
    "\n",
    "    return A, APrev\n",
    "\n",
    "# weights = initialize_weights([2, 2, 1])\n",
    "# yHat, A1 = forward_propogate(X[0], weights)\n",
    "# print(yHat.shape)\n",
    "# print(A1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, learningRate, y, yHat, A1, Xi):\n",
    "    # using gradient descent\n",
    "    weights['W2'][0][0] = weights['W2'][0][0] + learningRate * 2 * (y - yHat) * A1[0]\n",
    "    weights['W2'][1][0] = weights['W2'][1][0] + learningRate * 2 * (y - yHat) * A1[1]\n",
    "    weights['B2'][0] = weights['B2'][0] + learningRate * 2 * (y - yHat)\n",
    "\n",
    "    weights['W1'][0][0] = weights['W1'][0][0] + learningRate * 2 * (y - yHat) * weights['W2'][0][0] * Xi[0]\n",
    "    weights['W1'][1][0] = weights['W1'][1][0] + learningRate * 2 * (y - yHat) * weights['W2'][0][0] * Xi[1]\n",
    "    weights['B1'][0] = weights['B1'][0] + learningRate * 2 * (y - yHat) * weights['W2'][0][0]\n",
    "\n",
    "    weights['W1'][0][1] = weights['W1'][0][1] + learningRate * 2 * (y - yHat) * weights['W2'][1][0] * Xi[0]\n",
    "    weights['W1'][1][1] = weights['W1'][1][1] + learningRate * 2 * (y - yHat) * weights['W2'][1][0] * Xi[1]\n",
    "    weights['B1'][1] = weights['B1'][1] + learningRate * 2 * (y - yHat) * weights['W2'][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -  4 Loss -  26.249691774703265\n",
      "Epoch -  4 Loss -  19.19634375189233\n",
      "Epoch -  4 Loss -  9.702531836210806\n",
      "Epoch -  4 Loss -  3.0274162602080916\n",
      "Epoch -  4 Loss -  1.0597082587765176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.27790431, 0.27790431],\n",
       "        [0.40579137, 0.40579137]]),\n",
       " 'B1': array([0.0295198, 0.0295198]),\n",
       " 'W2': array([[0.46411039],\n",
       "        [0.46411039]]),\n",
       " 'B2': array([0.11664796])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the neural network\n",
    "epochs = 5\n",
    "learningRate = 0.001\n",
    "nnDims = [2, 2, 1]\n",
    "weights = initialize_weights(nnDims)\n",
    "\n",
    "# for each epoch\n",
    "for step in range(epochs):\n",
    "    # create an empty array to save loss for each student\n",
    "    loss = []\n",
    "    # loop through each student and perform forward/back propogation\n",
    "    for i in range(X.shape[0]):\n",
    "        yHat, A1 = forward_propogate(X[i], weights)\n",
    "        loss.append((y[i] - yHat[0]) ** 2)\n",
    "        update_weights(weights, learningRate, y[i], yHat[0], A1, X[i])\n",
    "\n",
    "    print('Epoch - ',i+1,'Loss - ',np.array(loss).mean())\n",
    "\n",
    "weights       \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try the same using Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, activation='linear', input_dim=2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.1, 0.1],\n",
       "        [0.1, 0.1]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[0.1],\n",
       "        [0.1]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_weights([np.array([[0.1 , 0.1],\n",
    "        [0.1,  0.1]], dtype=np.float32),\n",
    " np.array([0., 0.], dtype=np.float32),\n",
    " np.array([[0.1],\n",
    "        [0.1]], dtype=np.float32),\n",
    " np.array([0.], dtype=np.float32)])\n",
    "\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1404\n",
      "Epoch 2/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1413\n",
      "Epoch 3/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1340\n",
      "Epoch 4/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1265\n",
      "Epoch 5/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1319\n",
      "Epoch 6/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1177\n",
      "Epoch 7/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1123\n",
      "Epoch 8/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1144\n",
      "Epoch 9/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1131\n",
      "Epoch 10/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1029\n",
      "Epoch 11/60\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0998\n",
      "Epoch 12/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0940\n",
      "Epoch 13/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0886\n",
      "Epoch 14/60\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0879\n",
      "Epoch 15/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0818\n",
      "Epoch 16/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0808\n",
      "Epoch 17/60\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0749\n",
      "Epoch 18/60\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0769\n",
      "Epoch 19/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0713\n",
      "Epoch 20/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0665\n",
      "Epoch 21/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0651\n",
      "Epoch 22/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0679\n",
      "Epoch 23/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0623\n",
      "Epoch 24/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0587\n",
      "Epoch 25/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0630\n",
      "Epoch 26/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0589\n",
      "Epoch 27/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0543\n",
      "Epoch 28/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0519\n",
      "Epoch 29/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0587\n",
      "Epoch 30/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0523\n",
      "Epoch 31/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0480\n",
      "Epoch 32/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0495\n",
      "Epoch 33/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0477\n",
      "Epoch 34/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0456\n",
      "Epoch 35/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0461\n",
      "Epoch 36/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0454\n",
      "Epoch 37/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0428\n",
      "Epoch 38/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0420\n",
      "Epoch 39/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0432\n",
      "Epoch 40/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0407\n",
      "Epoch 41/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0399\n",
      "Epoch 42/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0394\n",
      "Epoch 43/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0395\n",
      "Epoch 44/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0370\n",
      "Epoch 45/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0392\n",
      "Epoch 46/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0369\n",
      "Epoch 47/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0390\n",
      "Epoch 48/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0370\n",
      "Epoch 49/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0354\n",
      "Epoch 50/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0375\n",
      "Epoch 51/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0386\n",
      "Epoch 52/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0355\n",
      "Epoch 53/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0402\n",
      "Epoch 54/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0393\n",
      "Epoch 55/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0353\n",
      "Epoch 56/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0344\n",
      "Epoch 57/60\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0358\n",
      "Epoch 58/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0377\n",
      "Epoch 59/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0387\n",
      "Epoch 60/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9468670f90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=60, verbose=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
